{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "import os\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74461814",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Set the base path\n",
    "    base_path = \"dataset/\"\n",
    "    \n",
    "    # Load all three CSV files with explicit paths\n",
    "    sales = pd.read_csv(os.path.join(base_path, \"K_class_sales_clean.csv\"))\n",
    "    prices = pd.read_csv(os.path.join(base_path, \"Price_Agriculture_commodities_Week.csv\"))\n",
    "    state = pd.read_csv(os.path.join(base_path, \"state.csv\"))\n",
    "    \n",
    "    print(\" Data loaded successfully from dataset/csv files directory!\")\n",
    "    print(f\"Sales data shape: {sales.shape}\")\n",
    "    print(f\"Prices data shape: {prices.shape}\")\n",
    "    print(f\"State data shape: {state.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\" Error: {e}\")\n",
    "    print(\"Please verify:\")\n",
    "    print(f\"1. The directory 'dataset/csv files' exists\")\n",
    "    print(\"2. It contains these exact files:\")\n",
    "    print(\"   - K_class_sales_clean.csv\")\n",
    "    print(\"   - Price_Agriculture_commodities_Week.csv\")\n",
    "    print(\"   - state.csv\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except Exception as e:\n",
    "    print(f\" Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a26101",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(df in globals() for df in ['sales', 'prices', 'state']):\n",
    "    print(\"\\n Sales Data Preview:\")\n",
    "    display(sales.head(2))\n",
    "    print(\"\\nMissing values:\", sales.isna().sum().sum())\n",
    "    \n",
    "    print(\"\\n Prices Data Preview:\")\n",
    "    display(prices.head(2))\n",
    "    print(\"\\nMissing values:\", prices.isna().sum().sum())\n",
    "    \n",
    "    print(\"\\n State Data Preview:\")\n",
    "    display(state.head(2))\n",
    "    print(\"\\nMissing values:\", state.isna().sum().sum())\n",
    "else:\n",
    "    print(\"Skipping exploration - data not loaded properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76284c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(df in globals() for df in ['sales', 'prices', 'state']):\n",
    "    try:\n",
    "        # Convert dates with error handling\n",
    "        sales['date'] = pd.to_datetime(sales['date'], errors='coerce')\n",
    "        prices['date'] = pd.to_datetime(prices['date'], errors='coerce')\n",
    "        \n",
    "        # Extract temporal features\n",
    "        sales['month'] = sales['date'].dt.month\n",
    "        sales['year'] = sales['date'].dt.year\n",
    "        prices['week'] = prices['date'].dt.isocalendar().week\n",
    "        \n",
    "        # Merge datasets\n",
    "        merged_df = pd.merge(\n",
    "            sales,\n",
    "            prices,\n",
    "            on=['commodity', 'date'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        final_df = pd.merge(\n",
    "            merged_df,\n",
    "            state,\n",
    "            on='state',\n",
    "            how='left'\n",
    "        )\n",
    "       # Handle missing values\n",
    "        final_df['price'] = final_df['price'].fillna(final_df['price'].median())\n",
    "        final_df['sales'] = final_df['sales'].fillna(final_df['sales'].median())\n",
    "        \n",
    "        # Feature engineering\n",
    "        final_df['price_per_unit'] = final_df['price'] / final_df['quantity']\n",
    "        final_df['sales_velocity'] = final_df['sales'] / final_df['quantity']\n",
    "        \n",
    "        print(\"\\nâœ… Final merged dataset shape:\", final_df.shape)\n",
    "        display(final_df.head(2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error during data processing: {e}\")\n",
    "else:\n",
    "    print(\"Skipping data processing - required data not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'final_df' in globals():\n",
    "    try:\n",
    "        sample_data = {\n",
    "            'commodity': ['Tomato'],  # Match exact commodity names from your data\n",
    "            'state': ['Gujarat'],\n",
    "            'month': [6],\n",
    "            'year': [2023],\n",
    "            'quantity': [100],\n",
    "            'week': [25]\n",
    "        }\n",
    "        \n",
    "        sample_df = pd.DataFrame(sample_data)\n",
    "        \n",
    "        required_columns = ['commodity', 'state', 'month', 'year', 'quantity', 'week']\n",
    "        if all(col in sample_df.columns for col in required_columns):\n",
    "            print(\"\\nðŸ”® Sample Prediction for:\")\n",
    "            display(sample_df)\n",
    "            \n",
    "            if 'price_pipeline' in globals():\n",
    "                price_pred = price_pipeline.predict(sample_df)\n",
    "                print(f\"Predicted Price per Unit: â‚¹{price_pred[0]:.2f}\")\n",
    "            else:\n",
    "                print(\"Price model not trained yet\")\n",
    "                \n",
    "            if 'demand_pipeline' in globals():\n",
    "                demand_pred = demand_pipeline.predict(sample_df)\n",
    "                print(f\"Predicted Demand: {demand_pred[0]:.0f} units\")\n",
    "            else:\n",
    "                print(\"Demand model not trained yet\")\n",
    "        else:\n",
    "            print(\"Sample data missing required columns\")\n",
    "    except Exception as e:\n",
    "        print(f\" Prediction error: {e}\")\n",
    "else:\n",
    "    print(\"Cannot make predictions - processed data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef11748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "X = final_df[['commodity', 'state', 'month', 'year', 'quantity', 'week']]\n",
    "y_price = final_df['price_per_unit']\n",
    "y_demand = final_df['sales']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_price_train, y_price_test, y_demand_train, y_demand_test = train_test_split(\n",
    "    X, y_price, y_demand, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['month', 'year', 'quantity', 'week']\n",
    "categorical_features = ['commodity', 'state']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"Preprocessor created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "price_pipeline.fit(X_train, y_price_train)\n",
    "\n",
    "# Evaluate\n",
    "price_pred = price_pipeline.predict(X_test)\n",
    "price_rmse = np.sqrt(mean_squared_error(y_price_test, price_pred))\n",
    "price_r2 = r2_score(y_price_test, price_pred)\n",
    "\n",
    "print(\"Price Prediction Results:\")\n",
    "print(f\"RMSE: {price_rmse:.2f}\")\n",
    "print(f\"R2 Score: {price_r2:.2f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importances = price_pipeline.named_steps['regressor'].feature_importances_\n",
    "feature_names = numeric_features + list(price_pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=feature_importances, y=feature_names)\n",
    "plt.title('Feature Importance for Price Prediction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8210751",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "demand_pipeline.fit(X_train, y_demand_train)\n",
    "\n",
    "# Evaluate\n",
    "demand_pred = demand_pipeline.predict(X_test)\n",
    "demand_rmse = np.sqrt(mean_squared_error(y_demand_test, demand_pred))\n",
    "demand_r2 = r2_score(y_demand_test, demand_pred)\n",
    "\n",
    "print(\"Demand Prediction Results:\")\n",
    "print(f\"RMSE: {demand_rmse:.2f}\")\n",
    "print(f\"R2 Score: {demand_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de925143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(price_pipeline, 'price_model.pkl')\n",
    "joblib.dump(demand_pipeline, 'demand_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "print(\"Models saved successfully:\")\n",
    "print(\"- price_model.pkl\")\n",
    "print(\"- demand_model.pkl\") \n",
    "print(\"- preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'commodity': ['Tomato'],\n",
    "    'state': ['Gujarat'],\n",
    "    'month': [6],\n",
    "    'year': [2023],\n",
    "    'quantity': [100],\n",
    "    'week': [25]\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "price_pred = price_pipeline.predict(sample_df)\n",
    "demand_pred = demand_pipeline.predict(sample_df)\n",
    "\n",
    "print(\"\\nSample Prediction for:\")\n",
    "display(sample_df)\n",
    "print(f\"Predicted Price per Unit: â‚¹{price_pred[0]:.2f}\")\n",
    "print(f\"Predicted Demand: {demand_pred[0]:.0f} units\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
